{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0908bb2-7d76-4043-991d-1831201cab91",
   "metadata": {},
   "source": [
    "# Importing/Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7158a4-108a-455e-bd52-aed869a031ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv-python-4.10.0.84.tar.gz (95.1 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "  Using cached opencv-python-headless-4.10.0.84.tar.gz (95.1 MB)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install necessary packages if not already installed\n",
    "try:\n",
    "    import cv2\n",
    "except ImportError:\n",
    "    !pip install opencv-python opencv-python-headless\n",
    "    import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5371f-89e6-4ac3-8598-96f3f8e15c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    !pip install numpy\n",
    "    import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7261bcb-9277-4d84-a89b-fe6abc630354",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825dcbd5-8d98-4567-ad1c-690413f35a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603a8df5-ff14-423f-8fd6-b07db18bc3c0",
   "metadata": {},
   "source": [
    "# Loading and Processing Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ef6d6-65d5-4ebd-ad77-f560aefb4e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "dataset_path = 'dataset/'\n",
    "\n",
    "# List of video files\n",
    "video_files = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if f.endswith('.mp4')]\n",
    "\n",
    "# Display the list of video files\n",
    "print(\"Video files:\", video_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f7de0-cefb-4925-a8e4-ff6c5dc782f1",
   "metadata": {},
   "source": [
    "# Loading the Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6092261b-10ed-4f05-a6eb-1e0622ca79cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load YOLOv3 model and weights\n",
    "yolo_net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "\n",
    "# Load the COCO names file\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = yolo_net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in yolo_net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Display the loaded classes\n",
    "print(\"Loaded classes:\", classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba275c-36e4-4725-b3b6-23ed4f230d8c",
   "metadata": {},
   "source": [
    "# Detecting Signals in Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23947db-1bfb-430d-8000-eba90fd7c17a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_signals(frame, net, output_layers, classes):\n",
    "    height, width, channels = frame.shape\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    \n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    \n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    result = []\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = confidences[i]\n",
    "            result.append((label, confidence, (x, y, w, h)))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Process each video and detect signals\n",
    "for video_file in video_files:\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    frame_count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        if frame_count % 30 == 0:  # Process every 30th frame\n",
    "            detections = detect_signals(frame, yolo_net, output_layers, classes)\n",
    "            \n",
    "            for (label, confidence, (x, y, w, h)) in detections:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"{label} {confidence:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            # Display the frame with detections\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    \n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd1d87-08b1-4b81-9b9c-8888c213c682",
   "metadata": {},
   "source": [
    "# Evaluation and Problems\n",
    "\n",
    "## Problems Encountered\n",
    "1. **False Positives and Negatives**: The model may detect non-signal objects as signals (false positives) or miss detecting actual signals (false negatives).\n",
    "2. **Lighting and Weather Conditions**: Variations in lighting and weather conditions can affect the detection accuracy.\n",
    "3. **Occlusions**: Signals that are partially obscured by other objects may not be detected.\n",
    "4. **Model Limitations**: The pre-trained model might not be trained specifically for traffic signals, leading to reduced accuracy.\n",
    "\n",
    "## System Capability\n",
    "The system can detect signals to a certain extent, but it may not be able to detect all signals accurately due to the aforementioned problems. Improving the training data and using models specifically trained on traffic signals could enhance the detection performance.\n",
    "\n",
    "## Why the System Might Fail\n",
    "1. **Training Data**: The model may not have been trained on a diverse enough dataset of traffic signals.\n",
    "2. **Real-Time Processing**: Processing videos in real-time can be computationally intensive and might lead to missed detections if the system cannot keep up with the video frame rate.\n",
    "3. **Environmental Factors**: Variations in the environment, such as shadows, reflections, and weather conditions, can adversely affect the detection accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
